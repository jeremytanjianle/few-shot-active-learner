{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seeds', 'single_entity.jsonl', 'v4.coref-separated.jsonl']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "os.chdir('..')\n",
    "os.listdir('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.dataset_readers.dataset_utils.span_utils import enumerate_spans\n",
    "from src.model import Sparta_Ent\n",
    "from src.data import Data_Handler\n",
    "\n",
    "handler = Data_Handler()\n",
    "model = Sparta_Ent()\n",
    "\n",
    "ref_text = \"The APT10 group (also known as Red Tears) is responsible and is linked to the North Korean nexus, and is charged with discharging the CryptoMix virus, retrieving money, phone numbers, details and credentials\"\n",
    "ref_doc = handler.process_sentence(ref_text)\n",
    "reference_encoding = model.encode_span(ref_doc, (1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.dataset_readers.dataset_utils.span_utils import enumerate_spans\n",
    "\n",
    "text = 'We believe TEMP.Mana, a Chinese cyber espionage group, is linked to infrastructure spoofing domains of at least two U.S. chemical manufacturers. Similar activity suspected of being tied to TEMP.Mana reinforces the risk to the chemical sector and related industries.'\n",
    "# text = \"During a compromise of a hospitality organization, which we attribute to FIN7, the attackers deployed various malicious payloads, including CARBANAK, BABYMETAL, and the PILLOWMINT point-of-sale (POS) malware. Notably, in this incident, FIN7 leveraged a seemingly compromised email account belonging one of the victim's suppliers to send a password-protected GRIFFON document to a restaurant manager. FIN7's shift to engaging in third-party compromise attacks marks a significant evolution in the group's operations and the manner in which organizations need to protect themselves against their attacks.\"\n",
    "# text = \"GREF Team is an innovative China-nexus cyber espionage operator that focuses on targeting energy, video game development studios, and high-tech companies in the U.S., South Korea, the Netherlands, Italy, France, and Japan. The group leverages a large library of malware tools, compromised digital certificates, and exploits. Besides being linked to a common supplier shared with other Chinese cyber espionage groups, GREF Team is believed to distribute its tools to other distinct China-based actors.\"\n",
    "# text = \"In 1905, a year sometimes described as his annus mirabilis ('miracle year'), Einstein published four groundbreaking papers.[12] These outlined the theory of the photoelectric effect, explained Brownian motion, introduced special relativity, and demonstrated mass-energy equivalence. Einstein thought that the laws of classical mechanics could no longer be reconciled with those of the electromagnetic field, which led him to develop his special theory of relativity. He then extended the theory to gravitational fields; he published a paper on general relativity in 1916, introducing his theory of gravitation. In 1917, he applied the general theory of relativity to model the structure of the universe.\"\n",
    "doc = handler.process_sentence(text)\n",
    "\n",
    "span_tuples = enumerate_spans(doc.doc, max_span_width=4)\n",
    "span_encodings = model.encode_spans(doc, span_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "to"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.doc[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "span_scores = {span_tuple:model.encoding_sim_score(query_encoding, reference_encoding) \n",
    "               for span_tuple, query_encoding in zip(span_tuples,span_encodings)}\n",
    "sorted_span_scores = {doc[k[0]:k[1]]: v for k, v in \n",
    "                      sorted(span_scores.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{group: tensor(0.6906, grad_fn=<MeanBackward0>),\n",
       " domains: tensor(0.6586, grad_fn=<MeanBackward0>),\n",
       " espionage group: tensor(0.6531, grad_fn=<MeanBackward0>),\n",
       " activity: tensor(0.6520, grad_fn=<MeanBackward0>),\n",
       " sector: tensor(0.6409, grad_fn=<MeanBackward0>),\n",
       " Similar activity: tensor(0.6348, grad_fn=<MeanBackward0>),\n",
       " cyber espionage group: tensor(0.6329, grad_fn=<MeanBackward0>),\n",
       " spoofing domains: tensor(0.6318, grad_fn=<MeanBackward0>),\n",
       " infrastructure spoofing domains: tensor(0.6311, grad_fn=<MeanBackward0>),\n",
       " group,: tensor(0.6309, grad_fn=<MeanBackward0>),\n",
       " activity suspected: tensor(0.6307, grad_fn=<MeanBackward0>),\n",
       " infrastructure: tensor(0.6291, grad_fn=<MeanBackward0>),\n",
       " espionage group,: tensor(0.6271, grad_fn=<MeanBackward0>),\n",
       " Similar activity suspected: tensor(0.6264, grad_fn=<MeanBackward0>),\n",
       " manufacturers: tensor(0.6246, grad_fn=<MeanBackward0>),\n",
       " to infrastructure spoofing domains: tensor(0.6228, grad_fn=<MeanBackward0>),\n",
       " Chinese cyber espionage group: tensor(0.6228, grad_fn=<MeanBackward0>),\n",
       " a: tensor(0.6224, grad_fn=<MeanBackward0>),\n",
       " infrastructure spoofing: tensor(0.6219, grad_fn=<MeanBackward0>),\n",
       " group, is: tensor(0.6209, grad_fn=<MeanBackward0>),\n",
       " infrastructure spoofing domains of: tensor(0.6205, grad_fn=<MeanBackward0>),\n",
       " cyber espionage group,: tensor(0.6202, grad_fn=<MeanBackward0>),\n",
       " espionage group, is: tensor(0.6198, grad_fn=<MeanBackward0>),\n",
       " manufacturers. Similar activity: tensor(0.6191, grad_fn=<MeanBackward0>),\n",
       " domains of: tensor(0.6184, grad_fn=<MeanBackward0>),\n",
       " spoofing domains of: tensor(0.6183, grad_fn=<MeanBackward0>),\n",
       " spoofing: tensor(0.6183, grad_fn=<MeanBackward0>),\n",
       " . Similar activity: tensor(0.6177, grad_fn=<MeanBackward0>),\n",
       " group, is linked: tensor(0.6176, grad_fn=<MeanBackward0>),\n",
       " Similar: tensor(0.6176, grad_fn=<MeanBackward0>),\n",
       " risk: tensor(0.6164, grad_fn=<MeanBackward0>),\n",
       " . Similar activity suspected: tensor(0.6160, grad_fn=<MeanBackward0>),\n",
       " Similar activity suspected of: tensor(0.6157, grad_fn=<MeanBackward0>),\n",
       " espionage: tensor(0.6155, grad_fn=<MeanBackward0>),\n",
       " chemical sector: tensor(0.6153, grad_fn=<MeanBackward0>),\n",
       " activity suspected of: tensor(0.6150, grad_fn=<MeanBackward0>),\n",
       " to infrastructure spoofing: tensor(0.6138, grad_fn=<MeanBackward0>),\n",
       " industries: tensor(0.6120, grad_fn=<MeanBackward0>),\n",
       " linked to infrastructure spoofing: tensor(0.6120, grad_fn=<MeanBackward0>),\n",
       " manufacturers. Similar: tensor(0.6108, grad_fn=<MeanBackward0>),\n",
       " industries.: tensor(0.6106, grad_fn=<MeanBackward0>),\n",
       " .: tensor(0.6099, grad_fn=<MeanBackward0>),\n",
       " suspected: tensor(0.6094, grad_fn=<MeanBackward0>),\n",
       " to infrastructure: tensor(0.6093, grad_fn=<MeanBackward0>),\n",
       " spoofing domains of at: tensor(0.6089, grad_fn=<MeanBackward0>),\n",
       " manufacturers.: tensor(0.6086, grad_fn=<MeanBackward0>),\n",
       " the risk: tensor(0.6084, grad_fn=<MeanBackward0>),\n",
       " linked to infrastructure: tensor(0.6077, grad_fn=<MeanBackward0>),\n",
       " TEMP.Mana: tensor(0.6076, grad_fn=<MeanBackward0>),\n",
       " related industries.: tensor(0.6075, grad_fn=<MeanBackward0>),\n",
       " a Chinese: tensor(0.6074, grad_fn=<MeanBackward0>),\n",
       " believe TEMP.Mana: tensor(0.6073, grad_fn=<MeanBackward0>),\n",
       " We believe TEMP.Mana: tensor(0.6071, grad_fn=<MeanBackward0>),\n",
       " We: tensor(0.6062, grad_fn=<MeanBackward0>),\n",
       " . Similar: tensor(0.6062, grad_fn=<MeanBackward0>),\n",
       " chemical manufacturers. Similar: tensor(0.6061, grad_fn=<MeanBackward0>),\n",
       " chemical manufacturers: tensor(0.6060, grad_fn=<MeanBackward0>),\n",
       " We believe: tensor(0.6059, grad_fn=<MeanBackward0>),\n",
       " sector and: tensor(0.6059, grad_fn=<MeanBackward0>),\n",
       " a Chinese cyber espionage: tensor(0.6057, grad_fn=<MeanBackward0>),\n",
       " believe: tensor(0.6055, grad_fn=<MeanBackward0>),\n",
       " sector and related industries: tensor(0.6055, grad_fn=<MeanBackward0>),\n",
       " related industries: tensor(0.6051, grad_fn=<MeanBackward0>),\n",
       " believe TEMP.Mana, a: tensor(0.6046, grad_fn=<MeanBackward0>),\n",
       " tied: tensor(0.6046, grad_fn=<MeanBackward0>),\n",
       " TEMP.Mana, a: tensor(0.6045, grad_fn=<MeanBackward0>),\n",
       " linked: tensor(0.6045, grad_fn=<MeanBackward0>),\n",
       " cyber espionage: tensor(0.6040, grad_fn=<MeanBackward0>),\n",
       " the chemical sector: tensor(0.6039, grad_fn=<MeanBackward0>),\n",
       " reinforces the risk: tensor(0.6037, grad_fn=<MeanBackward0>),\n",
       " is linked to infrastructure: tensor(0.6035, grad_fn=<MeanBackward0>),\n",
       " sector and related: tensor(0.6033, grad_fn=<MeanBackward0>),\n",
       " chemical manufacturers.: tensor(0.6032, grad_fn=<MeanBackward0>),\n",
       " TEMP.Mana, a Chinese: tensor(0.6032, grad_fn=<MeanBackward0>),\n",
       " We believe TEMP.Mana,: tensor(0.6028, grad_fn=<MeanBackward0>),\n",
       " domains of at: tensor(0.6027, grad_fn=<MeanBackward0>),\n",
       " a Chinese cyber: tensor(0.6024, grad_fn=<MeanBackward0>),\n",
       " believe TEMP.Mana,: tensor(0.6024, grad_fn=<MeanBackward0>),\n",
       " activity suspected of being: tensor(0.6022, grad_fn=<MeanBackward0>),\n",
       " TEMP.Mana,: tensor(0.6020, grad_fn=<MeanBackward0>),\n",
       " ,: tensor(0.6011, grad_fn=<MeanBackward0>),\n",
       " .: tensor(0.6005, grad_fn=<MeanBackward0>),\n",
       " chemical sector and: tensor(0.6005, grad_fn=<MeanBackward0>),\n",
       " the: tensor(0.6005, grad_fn=<MeanBackward0>),\n",
       " and related industries.: tensor(0.6002, grad_fn=<MeanBackward0>),\n",
       " Chinese cyber espionage: tensor(0.6001, grad_fn=<MeanBackward0>),\n",
       " chemical sector and related: tensor(0.5999, grad_fn=<MeanBackward0>),\n",
       " reinforces the: tensor(0.5994, grad_fn=<MeanBackward0>),\n",
       " , is linked: tensor(0.5993, grad_fn=<MeanBackward0>),\n",
       " , a: tensor(0.5993, grad_fn=<MeanBackward0>),\n",
       " reinforces: tensor(0.5989, grad_fn=<MeanBackward0>),\n",
       " reinforces the risk to: tensor(0.5984, grad_fn=<MeanBackward0>),\n",
       " related: tensor(0.5982, grad_fn=<MeanBackward0>),\n",
       " the risk to: tensor(0.5980, grad_fn=<MeanBackward0>),\n",
       " , is: tensor(0.5976, grad_fn=<MeanBackward0>),\n",
       " is linked: tensor(0.5976, grad_fn=<MeanBackward0>),\n",
       " , a Chinese: tensor(0.5976, grad_fn=<MeanBackward0>),\n",
       " , is linked to: tensor(0.5974, grad_fn=<MeanBackward0>),\n",
       " to the chemical sector: tensor(0.5973, grad_fn=<MeanBackward0>),\n",
       " linked to: tensor(0.5970, grad_fn=<MeanBackward0>),\n",
       " risk to: tensor(0.5968, grad_fn=<MeanBackward0>),\n",
       " , a Chinese cyber: tensor(0.5966, grad_fn=<MeanBackward0>),\n",
       " suspected of: tensor(0.5965, grad_fn=<MeanBackward0>),\n",
       " the chemical sector and: tensor(0.5957, grad_fn=<MeanBackward0>),\n",
       " two: tensor(0.5951, grad_fn=<MeanBackward0>),\n",
       " is linked to: tensor(0.5949, grad_fn=<MeanBackward0>),\n",
       " the risk to the: tensor(0.5938, grad_fn=<MeanBackward0>),\n",
       " and related industries: tensor(0.5937, grad_fn=<MeanBackward0>),\n",
       " cyber: tensor(0.5925, grad_fn=<MeanBackward0>),\n",
       " Chinese cyber: tensor(0.5925, grad_fn=<MeanBackward0>),\n",
       " Chinese: tensor(0.5924, grad_fn=<MeanBackward0>),\n",
       " risk to the: tensor(0.5916, grad_fn=<MeanBackward0>),\n",
       " risk to the chemical: tensor(0.5911, grad_fn=<MeanBackward0>),\n",
       " is: tensor(0.5907, grad_fn=<MeanBackward0>),\n",
       " suspected of being tied: tensor(0.5904, grad_fn=<MeanBackward0>),\n",
       " domains of at least: tensor(0.5900, grad_fn=<MeanBackward0>),\n",
       " chemical: tensor(0.5898, grad_fn=<MeanBackward0>),\n",
       " to: tensor(0.5895, grad_fn=<MeanBackward0>),\n",
       " TEMP.Mana reinforces the risk: tensor(0.5888, grad_fn=<MeanBackward0>),\n",
       " tied to: tensor(0.5887, grad_fn=<MeanBackward0>),\n",
       " ,: tensor(0.5878, grad_fn=<MeanBackward0>),\n",
       " chemical: tensor(0.5873, grad_fn=<MeanBackward0>),\n",
       " suspected of being: tensor(0.5856, grad_fn=<MeanBackward0>),\n",
       " the chemical: tensor(0.5854, grad_fn=<MeanBackward0>),\n",
       " TEMP.Mana reinforces the: tensor(0.5853, grad_fn=<MeanBackward0>),\n",
       " and related: tensor(0.5845, grad_fn=<MeanBackward0>),\n",
       " tied to TEMP.Mana reinforces: tensor(0.5844, grad_fn=<MeanBackward0>),\n",
       " being tied: tensor(0.5842, grad_fn=<MeanBackward0>),\n",
       " of being tied: tensor(0.5840, grad_fn=<MeanBackward0>),\n",
       " to TEMP.Mana reinforces the: tensor(0.5839, grad_fn=<MeanBackward0>),\n",
       " of: tensor(0.5836, grad_fn=<MeanBackward0>),\n",
       " TEMP.Mana reinforces: tensor(0.5832, grad_fn=<MeanBackward0>),\n",
       " to the chemical: tensor(0.5827, grad_fn=<MeanBackward0>),\n",
       " to TEMP.Mana reinforces: tensor(0.5819, grad_fn=<MeanBackward0>),\n",
       " of being tied to: tensor(0.5812, grad_fn=<MeanBackward0>),\n",
       " the: tensor(0.5811, grad_fn=<MeanBackward0>),\n",
       " being tied to: tensor(0.5804, grad_fn=<MeanBackward0>),\n",
       " tied to TEMP.Mana: tensor(0.5802, grad_fn=<MeanBackward0>),\n",
       " to the: tensor(0.5792, grad_fn=<MeanBackward0>),\n",
       " U.S. chemical manufacturers.: tensor(0.5789, grad_fn=<MeanBackward0>),\n",
       " being tied to TEMP.Mana: tensor(0.5782, grad_fn=<MeanBackward0>),\n",
       " of: tensor(0.5781, grad_fn=<MeanBackward0>),\n",
       " to: tensor(0.5772, grad_fn=<MeanBackward0>),\n",
       " TEMP.Mana: tensor(0.5769, grad_fn=<MeanBackward0>),\n",
       " to TEMP.Mana: tensor(0.5762, grad_fn=<MeanBackward0>),\n",
       " two U.S. chemical manufacturers: tensor(0.5750, grad_fn=<MeanBackward0>),\n",
       " of at: tensor(0.5747, grad_fn=<MeanBackward0>),\n",
       " of at least two: tensor(0.5741, grad_fn=<MeanBackward0>),\n",
       " of being: tensor(0.5737, grad_fn=<MeanBackward0>),\n",
       " least two: tensor(0.5735, grad_fn=<MeanBackward0>),\n",
       " at least two: tensor(0.5728, grad_fn=<MeanBackward0>),\n",
       " to: tensor(0.5727, grad_fn=<MeanBackward0>),\n",
       " U.S. chemical manufacturers: tensor(0.5717, grad_fn=<MeanBackward0>),\n",
       " at: tensor(0.5713, grad_fn=<MeanBackward0>),\n",
       " and: tensor(0.5709, grad_fn=<MeanBackward0>),\n",
       " of at least: tensor(0.5672, grad_fn=<MeanBackward0>),\n",
       " two U.S. chemical: tensor(0.5668, grad_fn=<MeanBackward0>),\n",
       " least two U.S. chemical: tensor(0.5647, grad_fn=<MeanBackward0>),\n",
       " being: tensor(0.5639, grad_fn=<MeanBackward0>),\n",
       " two U.S.: tensor(0.5627, grad_fn=<MeanBackward0>),\n",
       " at least two U.S.: tensor(0.5624, grad_fn=<MeanBackward0>),\n",
       " at least: tensor(0.5617, grad_fn=<MeanBackward0>),\n",
       " U.S. chemical: tensor(0.5611, grad_fn=<MeanBackward0>),\n",
       " least two U.S.: tensor(0.5609, grad_fn=<MeanBackward0>),\n",
       " U.S.: tensor(0.5546, grad_fn=<MeanBackward0>),\n",
       " least: tensor(0.5520, grad_fn=<MeanBackward0>)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_span_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'We believe TEMP.Mana, a Chinese cyber espionage group, is linked to infrastructure spoofing domains of at least two U.S. chemical manufacturers. Similar activity suspected of being tied to TEMP.Mana reinforces the risk to the chemical sector and related industries.',\n",
       " 'meta': {'source': 'fireeye-0-0'},\n",
       " 'spans': [{'start': 68,\n",
       "   'end': 99,\n",
       "   'label': 'ENT',\n",
       "   'token_start': 13,\n",
       "   'token_end': 16,\n",
       "   '_private_string': 'infrastructure spoofing domains'}]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading from jsonlines file\n",
    "with open('data/single_entity.jsonl', 'rb') as f:\n",
    "    lines = f.readlines()\n",
    "lines = [json.loads(line.decode('utf-8')) for line in lines]\n",
    "line = lines[0]\n",
    "text = line['text']\n",
    "line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Sparta ent model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.dataset_readers.dataset_utils.span_utils import enumerate_spans\n",
    "from src.model import Sparta_Ent\n",
    "from src.data import Data_Handler\n",
    "\n",
    "model = Sparta_Ent()\n",
    "handler = Data_Handler()\n",
    "doc = handler.process_sentence(text)\n",
    "\n",
    "span_tuples = enumerate_spans(doc.doc, max_span_width=7)\n",
    "span_encodings = model.encode_spans(doc, span_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁we', '▁believe', '▁', 'temp', '.', 'man', 'a', '▁', ',', '▁a']\n",
      "torch.Size([10, 768])\n"
     ]
    }
   ],
   "source": [
    "span_encoding = model.encode_span(doc, (0,4), verbose=True)\n",
    "print(span_encoding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `Doc_Span` and `Doc_Token` follow AllenNLP's inclusive spans instead of spacy's   exclusive spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "We believe TEMP.Mana, a"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "We believe TEMP.Mana, a"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.doc[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get reference encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_text = \"The APT10 group (also known as Red Tears) is responsible and is linked to the North Korean nexus, and is charged with discharging the CryptoMix virus, retrieving money, phone numbers, details and credentials\"\n",
    "ref_doc = handler.process_sentence(ref_text)\n",
    "reference_encoding = model.encode_span(ref_doc, (1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score the span candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rank(model, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "span_scores = {span_tuple:model.encoding_sim_score(query_encoding, reference_encoding) \n",
    "               for span_tuple, query_encoding in zip(span_tuples,span_encodings)}\n",
    "sorted_span_scores = {k: v for k, v in \n",
    "                      sorted(span_scores.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 7): tensor(4.8290, grad_fn=<SumBackward0>),\n",
       " (0, 6): tensor(4.7705, grad_fn=<SumBackward0>),\n",
       " (2, 8): tensor(4.7536, grad_fn=<SumBackward0>),\n",
       " (2, 7): tensor(4.4192, grad_fn=<SumBackward0>),\n",
       " (0, 5): tensor(4.4024, grad_fn=<SumBackward0>),\n",
       " (1, 6): tensor(4.3962, grad_fn=<SumBackward0>),\n",
       " (31, 37): tensor(4.1353, grad_fn=<SumBackward0>),\n",
       " (29, 35): tensor(4.0843, grad_fn=<SumBackward0>),\n",
       " (30, 36): tensor(4.0653, grad_fn=<SumBackward0>),\n",
       " (0, 4): tensor(4.0287, grad_fn=<SumBackward0>),\n",
       " (1, 5): tensor(4.0281, grad_fn=<SumBackward0>),\n",
       " (2, 6): tensor(3.9864, grad_fn=<SumBackward0>),\n",
       " (28, 34): tensor(3.9664, grad_fn=<SumBackward0>),\n",
       " (27, 33): tensor(3.8204, grad_fn=<SumBackward0>),\n",
       " (29, 34): tensor(3.7729, grad_fn=<SumBackward0>),\n",
       " (31, 36): tensor(3.7723, grad_fn=<SumBackward0>),\n",
       " (30, 35): tensor(3.7508, grad_fn=<SumBackward0>),\n",
       " (26, 32): tensor(3.7170, grad_fn=<SumBackward0>),\n",
       " (1, 4): tensor(3.6543, grad_fn=<SumBackward0>),\n",
       " (19, 25): tensor(3.6371, grad_fn=<SumBackward0>),\n",
       " (2, 5): tensor(3.6183, grad_fn=<SumBackward0>),\n",
       " (28, 33): tensor(3.5804, grad_fn=<SumBackward0>),\n",
       " (20, 26): tensor(3.5563, grad_fn=<SumBackward0>),\n",
       " (0, 3): tensor(3.5290, grad_fn=<SumBackward0>),\n",
       " (14, 20): tensor(3.5158, grad_fn=<SumBackward0>),\n",
       " (31, 35): tensor(3.4577, grad_fn=<SumBackward0>),\n",
       " (30, 34): tensor(3.4394, grad_fn=<SumBackward0>),\n",
       " (18, 24): tensor(3.4348, grad_fn=<SumBackward0>),\n",
       " (9, 15): tensor(3.4295, grad_fn=<SumBackward0>),\n",
       " (27, 32): tensor(3.4128, grad_fn=<SumBackward0>),\n",
       " (29, 33): tensor(3.3868, grad_fn=<SumBackward0>),\n",
       " (25, 31): tensor(3.3167, grad_fn=<SumBackward0>),\n",
       " (20, 25): tensor(3.2522, grad_fn=<SumBackward0>),\n",
       " (2, 4): tensor(3.2445, grad_fn=<SumBackward0>),\n",
       " (8, 14): tensor(3.2434, grad_fn=<SumBackward0>),\n",
       " (17, 23): tensor(3.2428, grad_fn=<SumBackward0>),\n",
       " (19, 24): tensor(3.2348, grad_fn=<SumBackward0>),\n",
       " (28, 32): tensor(3.1728, grad_fn=<SumBackward0>),\n",
       " (11, 17): tensor(3.1685, grad_fn=<SumBackward0>),\n",
       " (13, 19): tensor(3.1676, grad_fn=<SumBackward0>),\n",
       " (10, 16): tensor(3.1641, grad_fn=<SumBackward0>),\n",
       " (1, 3): tensor(3.1546, grad_fn=<SumBackward0>),\n",
       " (31, 34): tensor(3.1463, grad_fn=<SumBackward0>),\n",
       " (12, 18): tensor(3.1151, grad_fn=<SumBackward0>),\n",
       " (3, 9): tensor(3.1110, grad_fn=<SumBackward0>),\n",
       " (30, 33): tensor(3.0533, grad_fn=<SumBackward0>),\n",
       " (32, 38): tensor(3.0463, grad_fn=<SumBackward0>),\n",
       " (29, 32): tensor(2.9793, grad_fn=<SumBackward0>),\n",
       " (0, 2): tensor(2.9734, grad_fn=<SumBackward0>),\n",
       " (18, 23): tensor(2.9555, grad_fn=<SumBackward0>),\n",
       " (21, 27): tensor(2.9196, grad_fn=<SumBackward0>),\n",
       " (12, 17): tensor(2.9152, grad_fn=<SumBackward0>),\n",
       " (26, 31): tensor(2.9144, grad_fn=<SumBackward0>),\n",
       " (9, 14): tensor(2.9089, grad_fn=<SumBackward0>),\n",
       " (15, 21): tensor(2.9033, grad_fn=<SumBackward0>),\n",
       " (10, 15): tensor(2.8829, grad_fn=<SumBackward0>),\n",
       " (11, 16): tensor(2.8812, grad_fn=<SumBackward0>),\n",
       " (20, 24): tensor(2.8499, grad_fn=<SumBackward0>),\n",
       " (36, 42): tensor(2.8496, grad_fn=<SumBackward0>),\n",
       " (4, 10): tensor(2.8382, grad_fn=<SumBackward0>),\n",
       " (16, 22): tensor(2.8167, grad_fn=<SumBackward0>),\n",
       " (13, 18): tensor(2.7826, grad_fn=<SumBackward0>),\n",
       " (22, 28): tensor(2.7605, grad_fn=<SumBackward0>),\n",
       " (31, 33): tensor(2.7602, grad_fn=<SumBackward0>),\n",
       " (19, 23): tensor(2.7556, grad_fn=<SumBackward0>),\n",
       " (2, 3): tensor(2.7448, grad_fn=<SumBackward0>),\n",
       " (7, 13): tensor(2.7110, grad_fn=<SumBackward0>),\n",
       " (21, 26): tensor(2.6795, grad_fn=<SumBackward0>),\n",
       " (23, 29): tensor(2.6601, grad_fn=<SumBackward0>),\n",
       " (30, 32): tensor(2.6457, grad_fn=<SumBackward0>),\n",
       " (14, 19): tensor(2.6390, grad_fn=<SumBackward0>),\n",
       " (12, 16): tensor(2.6279, grad_fn=<SumBackward0>),\n",
       " (27, 31): tensor(2.6103, grad_fn=<SumBackward0>),\n",
       " (11, 15): tensor(2.6001, grad_fn=<SumBackward0>),\n",
       " (1, 2): tensor(2.5990, grad_fn=<SumBackward0>),\n",
       " (5, 11): tensor(2.5918, grad_fn=<SumBackward0>),\n",
       " (32, 37): tensor(2.5852, grad_fn=<SumBackward0>),\n",
       " (13, 17): tensor(2.5827, grad_fn=<SumBackward0>),\n",
       " (22, 27): tensor(2.5669, grad_fn=<SumBackward0>),\n",
       " (3, 8): tensor(2.5644, grad_fn=<SumBackward0>),\n",
       " (4, 9): tensor(2.5554, grad_fn=<SumBackward0>),\n",
       " (15, 20): tensor(2.5507, grad_fn=<SumBackward0>),\n",
       " (6, 12): tensor(2.5506, grad_fn=<SumBackward0>),\n",
       " (17, 22): tensor(2.5355, grad_fn=<SumBackward0>),\n",
       " (37, 42): tensor(2.5350, grad_fn=<SumBackward0>),\n",
       " (33, 39): tensor(2.5089, grad_fn=<SumBackward0>),\n",
       " (34, 40): tensor(2.4531, grad_fn=<SumBackward0>),\n",
       " (35, 41): tensor(2.3968, grad_fn=<SumBackward0>),\n",
       " (16, 21): tensor(2.3827, grad_fn=<SumBackward0>),\n",
       " (21, 25): tensor(2.3754, grad_fn=<SumBackward0>),\n",
       " (20, 23): tensor(2.3707, grad_fn=<SumBackward0>),\n",
       " (28, 31): tensor(2.3703, grad_fn=<SumBackward0>),\n",
       " (10, 14): tensor(2.3623, grad_fn=<SumBackward0>),\n",
       " (31, 32): tensor(2.3527, grad_fn=<SumBackward0>),\n",
       " (12, 15): tensor(2.3468, grad_fn=<SumBackward0>),\n",
       " (5, 10): tensor(2.3385, grad_fn=<SumBackward0>),\n",
       " (22, 26): tensor(2.3269, grad_fn=<SumBackward0>),\n",
       " (23, 28): tensor(2.3265, grad_fn=<SumBackward0>),\n",
       " (13, 16): tensor(2.2954, grad_fn=<SumBackward0>),\n",
       " (8, 13): tensor(2.2782, grad_fn=<SumBackward0>),\n",
       " (14, 18): tensor(2.2541, grad_fn=<SumBackward0>),\n",
       " (18, 22): tensor(2.2482, grad_fn=<SumBackward0>),\n",
       " (24, 30): tensor(2.2458, grad_fn=<SumBackward0>),\n",
       " (33, 38): tensor(2.2437, grad_fn=<SumBackward0>),\n",
       " (3, 7): tensor(2.2299, grad_fn=<SumBackward0>),\n",
       " (32, 36): tensor(2.2221, grad_fn=<SumBackward0>),\n",
       " (6, 11): tensor(2.2181, grad_fn=<SumBackward0>),\n",
       " (2, 2): tensor(2.1892, grad_fn=<SumBackward0>),\n",
       " (7, 12): tensor(2.1825, grad_fn=<SumBackward0>),\n",
       " (29, 31): tensor(2.1767, grad_fn=<SumBackward0>),\n",
       " (38, 42): tensor(2.1720, grad_fn=<SumBackward0>),\n",
       " (23, 27): tensor(2.1330, grad_fn=<SumBackward0>),\n",
       " (17, 21): tensor(2.1016, grad_fn=<SumBackward0>),\n",
       " (34, 39): tensor(2.1014, grad_fn=<SumBackward0>),\n",
       " (36, 41): tensor(2.0853, grad_fn=<SumBackward0>),\n",
       " (11, 14): tensor(2.0795, grad_fn=<SumBackward0>),\n",
       " (35, 40): tensor(2.0670, grad_fn=<SumBackward0>),\n",
       " (5, 9): tensor(2.0557, grad_fn=<SumBackward0>),\n",
       " (14, 17): tensor(2.0542, grad_fn=<SumBackward0>),\n",
       " (19, 22): tensor(2.0483, grad_fn=<SumBackward0>),\n",
       " (16, 20): tensor(2.0301, grad_fn=<SumBackward0>),\n",
       " (22, 25): tensor(2.0228, grad_fn=<SumBackward0>),\n",
       " (13, 15): tensor(2.0143, grad_fn=<SumBackward0>),\n",
       " (4, 8): tensor(2.0088, grad_fn=<SumBackward0>),\n",
       " (21, 24): tensor(1.9731, grad_fn=<SumBackward0>),\n",
       " (6, 10): tensor(1.9647, grad_fn=<SumBackward0>),\n",
       " (24, 29): tensor(1.9528, grad_fn=<SumBackward0>),\n",
       " (9, 13): tensor(1.9438, grad_fn=<SumBackward0>),\n",
       " (32, 35): tensor(1.9076, grad_fn=<SumBackward0>),\n",
       " (23, 26): tensor(1.8930, grad_fn=<SumBackward0>),\n",
       " (7, 11): tensor(1.8500, grad_fn=<SumBackward0>),\n",
       " (30, 31): tensor(1.8432, grad_fn=<SumBackward0>),\n",
       " (34, 38): tensor(1.8362, grad_fn=<SumBackward0>),\n",
       " (12, 14): tensor(1.8262, grad_fn=<SumBackward0>),\n",
       " (18, 21): tensor(1.8143, grad_fn=<SumBackward0>),\n",
       " (3, 6): tensor(1.7972, grad_fn=<SumBackward0>),\n",
       " (33, 37): tensor(1.7826, grad_fn=<SumBackward0>),\n",
       " (37, 41): tensor(1.7708, grad_fn=<SumBackward0>),\n",
       " (14, 16): tensor(1.7669, grad_fn=<SumBackward0>),\n",
       " (25, 30): tensor(1.7666, grad_fn=<SumBackward0>),\n",
       " (36, 40): tensor(1.7556, grad_fn=<SumBackward0>),\n",
       " (8, 12): tensor(1.7497, grad_fn=<SumBackward0>),\n",
       " (17, 20): tensor(1.7489, grad_fn=<SumBackward0>),\n",
       " (35, 39): tensor(1.7153, grad_fn=<SumBackward0>),\n",
       " (39, 42): tensor(1.7109, grad_fn=<SumBackward0>),\n",
       " (6, 9): tensor(1.6819, grad_fn=<SumBackward0>),\n",
       " (4, 7): tensor(1.6743, grad_fn=<SumBackward0>),\n",
       " (15, 19): tensor(1.6739, grad_fn=<SumBackward0>),\n",
       " (20, 22): tensor(1.6634, grad_fn=<SumBackward0>),\n",
       " (22, 24): tensor(1.6205, grad_fn=<SumBackward0>),\n",
       " (24, 28): tensor(1.6192, grad_fn=<SumBackward0>),\n",
       " (19, 21): tensor(1.6144, grad_fn=<SumBackward0>),\n",
       " (7, 10): tensor(1.5966, grad_fn=<SumBackward0>),\n",
       " (32, 34): tensor(1.5962, grad_fn=<SumBackward0>),\n",
       " (23, 25): tensor(1.5888, grad_fn=<SumBackward0>),\n",
       " (31, 31): tensor(1.5502, grad_fn=<SumBackward0>),\n",
       " (5, 8): tensor(1.5091, grad_fn=<SumBackward0>),\n",
       " (21, 23): tensor(1.4939, grad_fn=<SumBackward0>),\n",
       " (13, 14): tensor(1.4937, grad_fn=<SumBackward0>),\n",
       " (14, 15): tensor(1.4857, grad_fn=<SumBackward0>),\n",
       " (25, 29): tensor(1.4735, grad_fn=<SumBackward0>),\n",
       " (18, 20): tensor(1.4616, grad_fn=<SumBackward0>),\n",
       " (35, 38): tensor(1.4501, grad_fn=<SumBackward0>),\n",
       " (40, 42): tensor(1.4457, grad_fn=<SumBackward0>),\n",
       " (37, 40): tensor(1.4410, grad_fn=<SumBackward0>),\n",
       " (3, 5): tensor(1.4291, grad_fn=<SumBackward0>),\n",
       " (24, 27): tensor(1.4257, grad_fn=<SumBackward0>),\n",
       " (33, 36): tensor(1.4196, grad_fn=<SumBackward0>),\n",
       " (8, 11): tensor(1.4172, grad_fn=<SumBackward0>),\n",
       " (9, 12): tensor(1.4152, grad_fn=<SumBackward0>),\n",
       " (38, 41): tensor(1.4078, grad_fn=<SumBackward0>),\n",
       " (36, 39): tensor(1.4039, grad_fn=<SumBackward0>),\n",
       " (10, 13): tensor(1.3972, grad_fn=<SumBackward0>),\n",
       " (34, 37): tensor(1.3751, grad_fn=<SumBackward0>),\n",
       " (26, 30): tensor(1.3643, grad_fn=<SumBackward0>),\n",
       " (7, 9): tensor(1.3138, grad_fn=<SumBackward0>),\n",
       " (15, 18): tensor(1.2890, grad_fn=<SumBackward0>),\n",
       " (19, 20): tensor(1.2617, grad_fn=<SumBackward0>),\n",
       " (4, 6): tensor(1.2416, grad_fn=<SumBackward0>),\n",
       " (20, 21): tensor(1.2294, grad_fn=<SumBackward0>),\n",
       " (32, 33): tensor(1.2101, grad_fn=<SumBackward0>),\n",
       " (23, 24): tensor(1.1866, grad_fn=<SumBackward0>),\n",
       " (24, 26): tensor(1.1857, grad_fn=<SumBackward0>),\n",
       " (5, 7): tensor(1.1746, grad_fn=<SumBackward0>),\n",
       " (8, 10): tensor(1.1639, grad_fn=<SumBackward0>),\n",
       " (16, 19): tensor(1.1533, grad_fn=<SumBackward0>),\n",
       " (22, 23): tensor(1.1412, grad_fn=<SumBackward0>),\n",
       " (25, 28): tensor(1.1400, grad_fn=<SumBackward0>),\n",
       " (36, 38): tensor(1.1387, grad_fn=<SumBackward0>),\n",
       " (6, 8): tensor(1.1353, grad_fn=<SumBackward0>),\n",
       " (11, 13): tensor(1.1144, grad_fn=<SumBackward0>),\n",
       " (33, 35): tensor(1.1051, grad_fn=<SumBackward0>),\n",
       " (41, 42): tensor(1.0940, grad_fn=<SumBackward0>),\n",
       " (37, 39): tensor(1.0893, grad_fn=<SumBackward0>),\n",
       " (15, 17): tensor(1.0891, grad_fn=<SumBackward0>),\n",
       " (9, 11): tensor(1.0827, grad_fn=<SumBackward0>),\n",
       " (38, 40): tensor(1.0780, grad_fn=<SumBackward0>),\n",
       " (26, 29): tensor(1.0712, grad_fn=<SumBackward0>),\n",
       " (27, 30): tensor(1.0602, grad_fn=<SumBackward0>),\n",
       " (3, 4): tensor(1.0553, grad_fn=<SumBackward0>),\n",
       " (34, 36): tensor(1.0121, grad_fn=<SumBackward0>),\n",
       " (35, 37): tensor(0.9890, grad_fn=<SumBackward0>),\n",
       " (14, 14): tensor(0.9651, grad_fn=<SumBackward0>),\n",
       " (39, 41): tensor(0.9467, grad_fn=<SumBackward0>),\n",
       " (25, 27): tensor(0.9464, grad_fn=<SumBackward0>),\n",
       " (24, 25): tensor(0.8816, grad_fn=<SumBackward0>),\n",
       " (8, 9): tensor(0.8811, grad_fn=<SumBackward0>),\n",
       " (20, 20): tensor(0.8768, grad_fn=<SumBackward0>),\n",
       " (4, 5): tensor(0.8735, grad_fn=<SumBackward0>),\n",
       " (17, 19): tensor(0.8721, grad_fn=<SumBackward0>),\n",
       " (10, 12): tensor(0.8686, grad_fn=<SumBackward0>),\n",
       " (12, 13): tensor(0.8610, grad_fn=<SumBackward0>),\n",
       " (9, 10): tensor(0.8294, grad_fn=<SumBackward0>),\n",
       " (37, 38): tensor(0.8241, grad_fn=<SumBackward0>),\n",
       " (28, 30): tensor(0.8201, grad_fn=<SumBackward0>),\n",
       " (32, 32): tensor(0.8025, grad_fn=<SumBackward0>),\n",
       " (15, 16): tensor(0.8017, grad_fn=<SumBackward0>),\n",
       " (6, 7): tensor(0.8009, grad_fn=<SumBackward0>),\n",
       " (33, 34): tensor(0.7936, grad_fn=<SumBackward0>),\n",
       " (21, 22): tensor(0.7866, grad_fn=<SumBackward0>),\n",
       " (0, 1): tensor(0.7841, grad_fn=<SumBackward0>),\n",
       " (16, 18): tensor(0.7684, grad_fn=<SumBackward0>),\n",
       " (7, 8): tensor(0.7672, grad_fn=<SumBackward0>),\n",
       " (27, 29): tensor(0.7671, grad_fn=<SumBackward0>),\n",
       " (42, 42): tensor(0.7643, grad_fn=<SumBackward0>),\n",
       " (5, 6): tensor(0.7419, grad_fn=<SumBackward0>),\n",
       " (26, 28): tensor(0.7377, grad_fn=<SumBackward0>),\n",
       " (38, 39): tensor(0.7263, grad_fn=<SumBackward0>),\n",
       " (23, 23): tensor(0.7073, grad_fn=<SumBackward0>),\n",
       " (25, 26): tensor(0.7064, grad_fn=<SumBackward0>),\n",
       " (34, 35): tensor(0.6975, grad_fn=<SumBackward0>),\n",
       " (40, 41): tensor(0.6815, grad_fn=<SumBackward0>),\n",
       " (36, 37): tensor(0.6776, grad_fn=<SumBackward0>),\n",
       " (29, 30): tensor(0.6266, grad_fn=<SumBackward0>),\n",
       " (35, 36): tensor(0.6260, grad_fn=<SumBackward0>),\n",
       " (39, 40): tensor(0.6169, grad_fn=<SumBackward0>),\n",
       " (11, 12): tensor(0.5858, grad_fn=<SumBackward0>),\n",
       " (18, 19): tensor(0.5848, grad_fn=<SumBackward0>),\n",
       " (16, 17): tensor(0.5685, grad_fn=<SumBackward0>),\n",
       " (3, 3): tensor(0.5556, grad_fn=<SumBackward0>),\n",
       " (9, 9): tensor(0.5466, grad_fn=<SumBackward0>),\n",
       " (26, 27): tensor(0.5442, grad_fn=<SumBackward0>),\n",
       " (10, 11): tensor(0.5361, grad_fn=<SumBackward0>),\n",
       " (13, 13): tensor(0.5285, grad_fn=<SumBackward0>),\n",
       " (28, 29): tensor(0.5271, grad_fn=<SumBackward0>),\n",
       " (15, 15): tensor(0.5206, grad_fn=<SumBackward0>),\n",
       " (4, 4): tensor(0.4997, grad_fn=<SumBackward0>),\n",
       " (17, 18): tensor(0.4872, grad_fn=<SumBackward0>),\n",
       " (24, 24): tensor(0.4793, grad_fn=<SumBackward0>),\n",
       " (38, 38): tensor(0.4611, grad_fn=<SumBackward0>),\n",
       " (22, 22): tensor(0.4339, grad_fn=<SumBackward0>),\n",
       " (27, 28): tensor(0.4336, grad_fn=<SumBackward0>),\n",
       " (7, 7): tensor(0.4328, grad_fn=<SumBackward0>),\n",
       " (1, 1): tensor(0.4098, grad_fn=<SumBackward0>),\n",
       " (33, 33): tensor(0.4076, grad_fn=<SumBackward0>),\n",
       " (25, 25): tensor(0.4023, grad_fn=<SumBackward0>),\n",
       " (34, 34): tensor(0.3861, grad_fn=<SumBackward0>),\n",
       " (19, 19): tensor(0.3849, grad_fn=<SumBackward0>),\n",
       " (0, 0): tensor(0.3744, grad_fn=<SumBackward0>),\n",
       " (5, 5): tensor(0.3738, grad_fn=<SumBackward0>),\n",
       " (6, 6): tensor(0.3681, grad_fn=<SumBackward0>),\n",
       " (37, 37): tensor(0.3630, grad_fn=<SumBackward0>),\n",
       " (21, 21): tensor(0.3526, grad_fn=<SumBackward0>),\n",
       " (40, 40): tensor(0.3517, grad_fn=<SumBackward0>),\n",
       " (8, 8): tensor(0.3345, grad_fn=<SumBackward0>),\n",
       " (29, 29): tensor(0.3335, grad_fn=<SumBackward0>),\n",
       " (12, 12): tensor(0.3325, grad_fn=<SumBackward0>),\n",
       " (41, 41): tensor(0.3298, grad_fn=<SumBackward0>),\n",
       " (36, 36): tensor(0.3146, grad_fn=<SumBackward0>),\n",
       " (35, 35): tensor(0.3114, grad_fn=<SumBackward0>),\n",
       " (26, 26): tensor(0.3041, grad_fn=<SumBackward0>),\n",
       " (30, 30): tensor(0.2930, grad_fn=<SumBackward0>),\n",
       " (17, 17): tensor(0.2873, grad_fn=<SumBackward0>),\n",
       " (10, 10): tensor(0.2828, grad_fn=<SumBackward0>),\n",
       " (16, 16): tensor(0.2812, grad_fn=<SumBackward0>),\n",
       " (39, 39): tensor(0.2652, grad_fn=<SumBackward0>),\n",
       " (11, 11): tensor(0.2533, grad_fn=<SumBackward0>),\n",
       " (27, 27): tensor(0.2400, grad_fn=<SumBackward0>),\n",
       " (18, 18): tensor(0.1999, grad_fn=<SumBackward0>),\n",
       " (28, 28): tensor(0.1935, grad_fn=<SumBackward0>)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_span_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy line to doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TEMP.Mana, a Chinese cyber espionage group'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Doc_Tokens:\n",
    "    def __init__(self, doc, fullword_tokens, subword_tokens, subword_idx):\n",
    "        self.doc = doc\n",
    "        self.fullword_tokens = fullword_tokens\n",
    "        self.subword_tokens = subword_tokens\n",
    "        self.subword_idx = subword_idx\n",
    "\n",
    "    def __getitem__(self, val):\n",
    "        \"\"\"\n",
    "        Slice the doc. This is wrt to AllenNLP's inclusive spans.\n",
    "        Meaning that it is not compatible with Spacy's exclusive spans\n",
    "        \n",
    "        For example, the input doc[0:4] in allennlp's inclusive span \n",
    "        will return the equivalent of self.doc[0:5] in spacy's terms\n",
    "\n",
    "        reference for __getitem__:\n",
    "        https://stackoverflow.com/questions/2936863/implementing-slicing-in-getitem\n",
    "        \"\"\"\n",
    "        if isinstance(val, slice):\n",
    "            # +1 because allennlp spans are inclusive\n",
    "            return self.doc[val.start: val.stop+1]\n",
    "            if val.stop == val.start:\n",
    "                return self.doc[val.start: val.stop+1]\n",
    "            else:\n",
    "                return self.doc[val.start: val.stop]\n",
    "        else:\n",
    "            return self.doc[val]\n",
    "        \n",
    "class Doc_Span(Doc_Tokens):\n",
    "    def __init__(self, doc_tokens:Doc_Tokens, span_tuple:tuple):\n",
    "        self.doc = doc_tokens.doc\n",
    "        self.fullword_tokens = doc_tokens.fullword_tokens\n",
    "        self.subword_tokens = doc_tokens.subword_tokens\n",
    "        self.subword_idx = doc_tokens.subword_idx\n",
    "        self.span_tuple = span_tuple\n",
    "        self.span_text = self.doc[self.span_tuple[0]:self.span_tuple[1]+1].text\n",
    "\n",
    "doc_span = Doc_Span(doc, (2,8))\n",
    "doc_span.span_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'believe TEMP.Mana, a Chinese cyber espionage'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_span = Doc_Span(doc, (1,7))\n",
    "doc_span.span_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparta loss\n",
    "input: Query, reference, Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 470 ms\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def brute_sum_tensors(list_of_tensors):\n",
    "    return torch.sum( torch.stack( list_of_tensors ) )\n",
    "\n",
    "def xentropy_l2r(model, query_span: Doc_Span, references: list, negatives: list):\n",
    "    \"\"\"\n",
    "    Cross-entropy learning to rank loss as defined in:\n",
    "    https://arxiv.org/pdf/2009.13013.pdf\n",
    "    \n",
    "    A stronger reference for this loss is eq (3) in:\n",
    "    https://papers.nips.cc/paper/2009/file/2f55707d4193dc27118a0f19a1985716-Paper.pdf\n",
    "    \n",
    "    # TODO: this should get batched\n",
    "    \"\"\"\n",
    "    # perform encoding\n",
    "    query_encoding = model.encode_span(query_span, query_span.span_tuple)\n",
    "    reference_encodings = [model.encode_span(reference_span, reference_span.span_tuple) \n",
    "                           for reference_span in references]  if type(references[0]) != torch.Tensor else references\n",
    "    negative_encodings = [model.encode_span(neg_span, neg_span.span_tuple) \n",
    "                         for neg_span in negatives] if type(negatives[0]) != torch.Tensor else negatives\n",
    "\n",
    "    # calc loss\n",
    "    pos_sim = [model.encoding_sim_score(query_encoding, reference_encoding) \n",
    "               for reference_encoding in reference_encodings]\n",
    "    neg_sim = [torch.exp( model.encoding_sim_score(query_encoding, negative_encoding) ) \n",
    "               for negative_encoding in negative_encodings]\n",
    "    loss = torch.log( brute_sum_tensors(neg_sim) ) - brute_sum_tensors(pos_sim)\n",
    "    return loss\n",
    "\n",
    "%time loss = xentropy_l2r(model, Doc_Span(doc, (2,8)), [Doc_Span(ref_doc, (1,2))]*2 ,[Doc_Span(doc, (1,7))]*2 )\n",
    "# loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intra document loss\n",
    "1 query and label against support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APT10 group\n",
      "TEMP.Mana, a Chinese cyber espionage group\n"
     ]
    }
   ],
   "source": [
    "references_spans = [Doc_Span( handler.process_sentence(ref_text), (1,2)) ]\n",
    "answer_spans = [Doc_Span(doc, (2,8))]\n",
    "print(references_spans[0].span_text)\n",
    "print(answer_spans[0].span_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.0098, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def intra_doc_loss(answer_spans: list, references_spans: list):\n",
    "    \n",
    "    # genereate correct encodings\n",
    "    answer_spans_encodings = model.encode_spans( answer_spans[0], [answer_span.span_tuple for answer_span in answer_spans] )\n",
    "    \n",
    "    # generate wrong spans\n",
    "    all_possible_spans = enumerate_spans( answer_spans[0].doc, max_span_width = 7)\n",
    "    all_wrong_spans = [span for span in all_possible_spans \n",
    "                       if span not in [answer_span.span_tuple for answer_span in answer_spans]]\n",
    "    all_wrong_span_encodings = model.encode_spans( answer_spans[0], all_wrong_spans )\n",
    "    \n",
    "    # iterate through references_spans & sum loss\n",
    "    losses = []\n",
    "    for reference in references_spans:\n",
    "        loss_ = xentropy_l2r(model, reference, answer_spans_encodings, all_wrong_span_encodings)\n",
    "        losses.append(loss_)\n",
    "        \n",
    "    return brute_sum_tensors(losses)\n",
    "\n",
    "intra_doc_loss(answer_spans, references_spans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interdocument loss\n",
    "support against support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "query = np.random.choice(references_spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = [references_span for references_span in references_spans if references_span != query]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
